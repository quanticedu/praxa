{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiTLh6Ul3O5O1Nmb8cRO0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanticedu/sample-rag-app/blob/main/SUNLight_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lesson 3: Vector Database\n"
      ],
      "metadata": {
        "id": "uz1fotPlr1m3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Getting Started\n",
        "Your code and data will run in the `/content` directory. Create a subdirectory there called `context_data` and upload the [context documents for the course]() into that directory. If you're new to Google Colab, download our [Getting Started with Colab]() guide.\n",
        "\n",
        "You'll also need an API key from Hugging Face. Go to their [signup page](https://huggingface.co/join), enter your email and a password, then complete your profile. Once you have an account and are signed in, go to [Settings | Access Tokens](https://huggingface.co/settings/tokens) then select \"New token\". You only need a read-type token (write tokens allow you to post to Hugging Face).\n",
        "\n",
        "Once you have your token, enter it below and run the code in the cell. Note that a command at the shell prompt (like `export`) is preceded with a bang `!`."
      ],
      "metadata": {
        "id": "9-Nc1lD3tYag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export HF_API_TOKEN=\"your-api-token\""
      ],
      "metadata": {
        "id": "f06PqYMTv61t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain touches all aspects of this app, so let's go ahead and install it now."
      ],
      "metadata": {
        "id": "GYxAfzSNzZSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install package-name"
      ],
      "metadata": {
        "id": "tokWSgM-zvDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Context Documents\n",
        "The first step in building the vector database is to load the context documents. Load them into a variable named `context_data`."
      ],
      "metadata": {
        "id": "hP7ReL0twnJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KY4CoAHVz_h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's verify that the documents loaded by printing the content of each page. Scroll to the end of a line to see what metadata the document loader includes."
      ],
      "metadata": {
        "id": "Tjgyps9f4uDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for page in context_data:\n",
        "  print(page)"
      ],
      "metadata": {
        "id": "vFtvWOhJ4y-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chunking\n",
        "Now it's time to split the documents into chunks that will work with the LLM's context window. Store them in a variable named `chunks`."
      ],
      "metadata": {
        "id": "m1RT2MMk6Jbj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRUcG95A8jqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify it worked by exploring how the documents were chunked."
      ],
      "metadata": {
        "id": "ofngPyLR_EXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Document Chunks: {len(chunks)}\\n\")\n",
        "print(chunks[0].metadata)\n",
        "print(chunks[0].page_content)\n",
        "\n",
        "print(\"Length of each chunk:\")\n",
        "\n",
        "for num, chunk in enumerate(chunks):\n",
        "  print(f\"Chunk {num} (from page {chunk.metadata['page'] + 1}): {len(chunk.page_content)} characters\")"
      ],
      "metadata": {
        "id": "mx_t2f8U-k9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to set up the embedding function. Assign it to a variable named `embedding_function`."
      ],
      "metadata": {
        "id": "RnR0lbf-CSm1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ln3cVD-XCWIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your model works by finding the embedding for a test sentence."
      ],
      "metadata": {
        "id": "XYCpOZU9DvI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embedding_function.embed_query(\"This is a test sentence.\")\n",
        "print(f\"Embedding length: {len(embedding)}\")\n",
        "print(f\"{embedding[:3]}, ... , {embedding[-3:]}\")"
      ],
      "metadata": {
        "id": "0RaQ_S0eDzix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time for the vector store. Assign it the name `chromadb`."
      ],
      "metadata": {
        "id": "wGeqzZA8IQqv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-KT3aALInxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now test it by executing a similarity search."
      ],
      "metadata": {
        "id": "5Pmh1FmFLIE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_chunks = chromadb.similarity_search(\"What are different modalities supported for Generative Artificial Intelligence?\")\n",
        "print(f\"Query retrieved {len(retrieved_chunks)} chunks.\")\n",
        "for chunk in retrieved_chunks:\n",
        "  print(f\"Chunk content: {chunk.page_content}\")\n",
        "  print(f\"Chunk metadata: {chunk.metadata}\")"
      ],
      "metadata": {
        "id": "6uwCgpxrLO1_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}