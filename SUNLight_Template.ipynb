{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanticedu/sample-rag-app/blob/main/SUNLight_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lesson 3: Vector Database\n"
      ],
      "metadata": {
        "id": "uz1fotPlr1m3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Getting Started\n",
        "If you're new to Google Colab, download and review the [Getting Started with Colab](https://uploads.smart.ly/assets/49f329a834468c6f6e9010cbf337a2753b22d35c245e49fc00d4b89e4ceb10fa/original/49f329a834468c6f6e9010cbf337a2753b22d35c245e49fc00d4b89e4ceb10fa.pdf) guide.\n",
        "\n",
        "Your code and data will run in the `/content` directory. Create a subdirectory in `/content` called `context_data` and upload the [context documents for the course](https://uploads.smart.ly/assets/b10a588ae693ff74daaf04058ce6254b05efd193f289f0a1cc01f9c934ee3d13/original/b10a588ae693ff74daaf04058ce6254b05efd193f289f0a1cc01f9c934ee3d13.zip) into `context_data`.\n",
        "\n",
        "You'll also need an API key from Hugging Face. Visit their [signup page](https://huggingface.co/join), enter your email and a password, then complete your profile. Once you have an account and are signed in, go to [Settings | Access Tokens](https://huggingface.co/settings/tokens) and select \"New token.\" Write tokens allow you to post to Hugging Face, which you won't be doing here, so you only need a read-type token.\n",
        "\n",
        "Once you have your token, enter it below and run the code in the cell by clicking the play button on its left."
      ],
      "metadata": {
        "id": "9-Nc1lD3tYag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"<your token>\""
      ],
      "metadata": {
        "id": "f06PqYMTv61t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain touches all aspects of this app, so let's go ahead and install it now."
      ],
      "metadata": {
        "id": "GYxAfzSNzZSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install package-name"
      ],
      "metadata": {
        "id": "tokWSgM-zvDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Context Documents\n",
        "The first step in building the vector database is to load the context documents. Load them into a variable named `context_data`."
      ],
      "metadata": {
        "id": "hP7ReL0twnJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KY4CoAHVz_h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's verify that the documents loaded by printing the content of each page. Scroll to the end of a line to see what metadata the document loader includes."
      ],
      "metadata": {
        "id": "Tjgyps9f4uDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for page in context_data:\n",
        "  print(page)"
      ],
      "metadata": {
        "id": "vFtvWOhJ4y-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chunking\n",
        "Now it's time to split the documents into chunks that will work with the LLM's context window. Store them in a variable named `chunks`."
      ],
      "metadata": {
        "id": "m1RT2MMk6Jbj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRUcG95A8jqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify it worked by exploring how the documents were chunked."
      ],
      "metadata": {
        "id": "ofngPyLR_EXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Document Chunks: {len(chunks)}\\n\")\n",
        "print(chunks[0].metadata)\n",
        "print(chunks[0].page_content)\n",
        "\n",
        "print(\"Length of each chunk:\")\n",
        "\n",
        "for num, chunk in enumerate(chunks):\n",
        "  print(f\"Chunk {num} (from page {chunk.metadata['page'] + 1}): {len(chunk.page_content)} characters\")"
      ],
      "metadata": {
        "id": "mx_t2f8U-k9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding\n",
        "\n",
        "Now it's time to set up the embedding function. Assign it to a variable named `embedding_function`."
      ],
      "metadata": {
        "id": "RnR0lbf-CSm1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ln3cVD-XCWIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your model works by finding the embedding for a test sentence."
      ],
      "metadata": {
        "id": "XYCpOZU9DvI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embedding_function.embed_query(\"This is a test sentence.\")\n",
        "print(f\"Embedding length: {len(embedding)}\")\n",
        "print(f\"{embedding[:3]}, ... , {embedding[-3:]}\")"
      ],
      "metadata": {
        "id": "0RaQ_S0eDzix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Persisting\n",
        "\n",
        "Now it's time for the vector store. Assign it the name `chromadb`."
      ],
      "metadata": {
        "id": "wGeqzZA8IQqv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-KT3aALInxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now test it by executing a similarity search."
      ],
      "metadata": {
        "id": "5Pmh1FmFLIE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_chunks = chromadb.similarity_search(\"Two people who take a vacation together.\")\n",
        "print(f\"Query retrieved {len(retrieved_chunks)} chunks.\")\n",
        "for chunk in retrieved_chunks:\n",
        "  print(f\"Chunk content: {chunk.page_content}\")\n",
        "  print(f\"Chunk metadata: {chunk.metadata}\")"
      ],
      "metadata": {
        "id": "6uwCgpxrLO1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lesson 4: LangChain and Language Models"
      ],
      "metadata": {
        "id": "-b4gTUZ6yPAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using the LangChain Model I/O Module\n",
        "Start by installing the packages we'll need."
      ],
      "metadata": {
        "id": "DQINfDvY2eSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install <packages>"
      ],
      "metadata": {
        "id": "7sawAQiG5N0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Getting the LLM\n",
        "Now we want to get the LLM."
      ],
      "metadata": {
        "id": "SLsPvc7t6Pqn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yvs5-3bE6rCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's invoke the LLM with a prompt it should be able to handle."
      ],
      "metadata": {
        "id": "yJ9gZIxR__Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"List Tawfiq al-Hakim's plays by title as a comma-separated list.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "xagZYN4GAQA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting up a Prompt Template\n",
        "We'll now build a simple prompt template to make our interface with the LLM a bit more generic."
      ],
      "metadata": {
        "id": "MEwwSFj5Dr5L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2gdIykGEBNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out!"
      ],
      "metadata": {
        "id": "0kXZPOpcEkvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)\n",
        "response = llm.invoke(prompt.format(playwright=\"Jez Butterworth\"))\n",
        "print(response)"
      ],
      "metadata": {
        "id": "oW-7mJBaEmdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Output Parsers\n",
        "While we're exploring the Model I/O module let's take a quick look at how the output parser in the Quickstart works."
      ],
      "metadata": {
        "id": "xL-a_WYkK_dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "response = output_parser.parse(llm.invoke(prompt.format(playwright=\"Jez Butterworth\")))\n",
        "print(response)"
      ],
      "metadata": {
        "id": "YG3g-nlTLXA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain Expression Language (LCEL)\n",
        "The \"Chain\" in \"LangChain\" refers to the ability to chain several actions into one invocation. This replaces your nested calls to `output_parser()`, `llm.invoke()`, and `prompt.format()`. Try to build a chain for what you have here."
      ],
      "metadata": {
        "id": "RYJ5TPaqPiD8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sj-_rm2dQNr1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}