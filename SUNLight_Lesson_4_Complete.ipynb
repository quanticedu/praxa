{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanticedu/sample-rag-app/blob/lesson-4-complete/SUNLight_Lesson_4_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lesson 3: Vector Database\n"
      ],
      "metadata": {
        "id": "uz1fotPlr1m3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Getting Started\n",
        "If you're new to Google Colab, download and review the [Getting Started with Colab](https://uploads.smart.ly/assets/49f329a834468c6f6e9010cbf337a2753b22d35c245e49fc00d4b89e4ceb10fa/original/49f329a834468c6f6e9010cbf337a2753b22d35c245e49fc00d4b89e4ceb10fa.pdf) guide.\n",
        "\n",
        "Your code and data will run in the `/content` directory. Create a subdirectory in `/content` called `context_data` and upload the [context documents for the course](https://uploads.smart.ly/assets/b10a588ae693ff74daaf04058ce6254b05efd193f289f0a1cc01f9c934ee3d13/original/b10a588ae693ff74daaf04058ce6254b05efd193f289f0a1cc01f9c934ee3d13.zip) into `context_data`.\n",
        "\n",
        "You'll also need an API key from Hugging Face. Visit their [signup page](https://huggingface.co/join), enter your email and a password, then complete your profile. Once you have an account and are signed in, go to [Settings | Access Tokens](https://huggingface.co/settings/tokens) and select \"New token.\" Write tokens allow you to post to Hugging Face, which you won't be doing here, so you only need a read-type token.\n",
        "\n",
        "Once you have your token, enter it below and run the code in the cell by clicking the play button on its left. Note that all commands at the shell prompt, such as `pip` below, should be preceded with a bang `!`."
      ],
      "metadata": {
        "id": "9-Nc1lD3tYag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"your-token-here\""
      ],
      "metadata": {
        "id": "f06PqYMTv61t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain touches all aspects of this app, so let's go ahead and install it now."
      ],
      "metadata": {
        "id": "GYxAfzSNzZSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.1.13 langchain-community==0.0.29 langchain-core==0.1.36"
      ],
      "metadata": {
        "id": "tokWSgM-zvDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Context Documents\n",
        "The first step in building the vector database is to load the context documents. Load them into a variable named `context_data`."
      ],
      "metadata": {
        "id": "hP7ReL0twnJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf==4.1.0\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "loader = PyPDFDirectoryLoader(\"./context_data\")\n",
        "context_data = loader.load()"
      ],
      "metadata": {
        "id": "KY4CoAHVz_h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's verify that the documents loaded by printing the content of each page. Scroll to the end of a line to see what metadata the document loader includes."
      ],
      "metadata": {
        "id": "Tjgyps9f4uDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for page in context_data:\n",
        "  print(page)"
      ],
      "metadata": {
        "id": "vFtvWOhJ4y-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chunking\n",
        "Now it's time to split the documents into chunks that will work with the LLM's context window. Store them in a variable named `chunks`."
      ],
      "metadata": {
        "id": "m1RT2MMk6Jbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-text-splitters==0.0.1\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False\n",
        ")\n",
        "chunks = text_splitter.split_documents(context_data)"
      ],
      "metadata": {
        "id": "zRUcG95A8jqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify it worked by exploring how the documents were chunked."
      ],
      "metadata": {
        "id": "ofngPyLR_EXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Document Chunks: {len(chunks)}\\n\")\n",
        "print(chunks[0].metadata)\n",
        "print(chunks[0].page_content)\n",
        "\n",
        "print(\"Length of each chunk:\")\n",
        "\n",
        "for num, chunk in enumerate(chunks):\n",
        "  print(f\"Chunk {num} (from page {chunk.metadata['page'] + 1}): {len(chunk.page_content)} characters\")"
      ],
      "metadata": {
        "id": "mx_t2f8U-k9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding\n",
        "\n",
        "Now it's time to set up the embedding function. Assign it to a variable named `embedding_function`."
      ],
      "metadata": {
        "id": "RnR0lbf-CSm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers==2.6.1\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "ln3cVD-XCWIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your model works by finding the embedding for a test sentence."
      ],
      "metadata": {
        "id": "XYCpOZU9DvI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embedding_function.embed_query(\"This is a test sentence.\")\n",
        "print(f\"Embedding length: {len(embedding)}\")\n",
        "print(f\"{embedding[:3]}, ... , {embedding[-3:]}\")"
      ],
      "metadata": {
        "id": "0RaQ_S0eDzix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Persisting\n",
        "\n",
        "Now it's time for the vector store. Assign it the name `chromadb`."
      ],
      "metadata": {
        "id": "wGeqzZA8IQqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb==0.4.24\n",
        "from langchain_community.vectorstores import Chroma\n",
        "chromadb = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embedding_function,\n",
        "    persist_directory='./chromadb'\n",
        ")\n",
        "chromadb.persist()"
      ],
      "metadata": {
        "id": "3-KT3aALInxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now test it by executing a similarity search."
      ],
      "metadata": {
        "id": "5Pmh1FmFLIE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_chunks = chromadb.similarity_search(\"Two people who take a vacation together.\")\n",
        "print(f\"Query retrieved {len(retrieved_chunks)} chunks.\")\n",
        "for chunk in retrieved_chunks:\n",
        "  print(f\"Chunk content: {chunk.page_content}\")\n",
        "  print(f\"Chunk metadata: {chunk.metadata}\")"
      ],
      "metadata": {
        "id": "6uwCgpxrLO1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lesson 4: LangChain and Language Models"
      ],
      "metadata": {
        "id": "-b4gTUZ6yPAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using the LangChain Model I/O Module\n",
        "Start by installing the packages we'll need."
      ],
      "metadata": {
        "id": "DQINfDvY2eSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub==0.20.3 transformers==4.38.2"
      ],
      "metadata": {
        "id": "7sawAQiG5N0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Getting the LLM\n",
        "Now we want to get the LLM."
      ],
      "metadata": {
        "id": "SLsPvc7t6Pqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    task=\"text-generation\",\n",
        "    model_kwargs={\n",
        "        \"max_new_tokens\": 512,\n",
        "        \"top_k\": 30,\n",
        "        \"temperature\": 0.1,\n",
        "        \"repetition_penalty\": 1.03,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "Yvs5-3bE6rCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's invoke the LLM with a prompt it should be able to handle."
      ],
      "metadata": {
        "id": "yJ9gZIxR__Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"List Tawfiq al-Hakim's plays by title as a comma-separated list.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "xagZYN4GAQA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting up a Prompt Template\n",
        "We'll now build a simple prompt template to make our interface with the LLM a bit more generic."
      ],
      "metadata": {
        "id": "MEwwSFj5Dr5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"List {playwright}'s plays by title as a comma-separated list.\")"
      ],
      "metadata": {
        "id": "r2gdIykGEBNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out!"
      ],
      "metadata": {
        "id": "0kXZPOpcEkvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)\n",
        "response = llm.invoke(prompt.format(playwright=\"Jez Butterworth\"))\n",
        "print(response)"
      ],
      "metadata": {
        "id": "oW-7mJBaEmdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Output Parsers\n",
        "While we're exploring the Model I/O module let's take a quick look at how the output parser in the Quickstart works."
      ],
      "metadata": {
        "id": "xL-a_WYkK_dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "response = output_parser.parse(llm.invoke(prompt.format(playwright=\"Jez Butterworth\")))\n",
        "print(response)"
      ],
      "metadata": {
        "id": "YG3g-nlTLXA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain Expression Language (LCEL)\n",
        "The \"Chain\" in \"LangChain\" refers to the ability to chain several actions into one invocation. This replaces your nested calls to `output_parser()`, `llm.invoke()`, and `prompt.format()`. Try to build a chain for what you have here."
      ],
      "metadata": {
        "id": "RYJ5TPaqPiD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | output_parser\n",
        "response = chain.invoke({\"playwright\" : \"Tawfiq al-Hakim\"})\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Sj-_rm2dQNr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lesson 5: RAG Using LangChain"
      ],
      "metadata": {
        "id": "R3VlXuSfB2_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build a Prompt Template\n",
        "We'll start with a prompt template that combines the context and original question and provides instructions to the model on how to use both."
      ],
      "metadata": {
        "id": "qrMBqouGB_5U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6LBTX5NCTo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the context, we'll use a *retriever*. It takes a string as the input query and returns a `list` of `Document` objects."
      ],
      "metadata": {
        "id": "t4vSm7m7FJVt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kEEdbwfMFqCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run it to see what it outputs."
      ],
      "metadata": {
        "id": "NvgeUSMPF3gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\"List Jez Butterworth's plays.\")"
      ],
      "metadata": {
        "id": "-TZ0fq9UF6CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final form we're going for is `chain.invoke(user_question)`. We'll need the `user_question` for two things in this prompt: the question itself and finding the context from the vector database. Doing multiple things to one input is the job of a `RunnableParallel`. Let's create one that does that."
      ],
      "metadata": {
        "id": "qgki18WqiXZj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "meXqYUTfieuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what that looks like."
      ],
      "metadata": {
        "id": "AlQnER6Cis8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_and_question.invoke(\"List Jez Butterworth's plays.\")"
      ],
      "metadata": {
        "id": "r8gW0YKlivfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the context docs in a prompt, we're going to need to convert them to a string. We'll use a `RunnablePassthrough` to assign that string to the `context` key the prompt needs. Note that the `question` attribute from `context_docs_and_question` gets passed through."
      ],
      "metadata": {
        "id": "Dr3BOS2tJvch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_context_docs(to_convert):\n",
        "    # Take the page_content attribute of each Document object\n",
        "    # and join them into one string, separated by two newlines.\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in to_convert[\"context_docs\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "QuTlQxcWJvIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how all this works with our prompt."
      ],
      "metadata": {
        "id": "2HfjcNldLqlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete_prompt_chain = context_and_question | convert_context | prompt\n",
        "complete_prompt_chain.invoke(\"List Jez Butterworth's plays.\")"
      ],
      "metadata": {
        "id": "tcTaUM1aLt-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll build the final chain for our app."
      ],
      "metadata": {
        "id": "dDzUuMVyMLF1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAiLsZ0gMPnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And run it to see what results we get."
      ],
      "metadata": {
        "id": "4Tx95TvIMW5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke(\"List Jez Butterworth's plays.\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "BwaDZ1jZMaBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll build a chain that passes the source citations, which were in the metadata field of the `list` of `Document` objects returned from the retriever. We'll use `RunnableParallel` to pass the `list` to the end of the chain while also passing it to a chain that builds the prompt and invokes the model."
      ],
      "metadata": {
        "id": "qiAIHm-WfIbp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdhhFAO4f-Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run it to see what we got."
      ],
      "metadata": {
        "id": "tCAcF-Y3glRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain_with_sources.invoke(\"List Jez Butterworth's plays.\")\n",
        "print(\"The docs used in this answer:\")\n",
        "print(\"\\n\".join(doc.metadata.__repr__() for doc in result[\"context_docs\"]))\n",
        "print(\"\\nThe answer:\")\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "id": "oc8HoXULp88X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}